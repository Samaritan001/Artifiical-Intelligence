{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24489f51",
   "metadata": {},
   "source": [
    "# Softmax\n",
    "## Forward Propagation\n",
    "Softmax layer: the activation function for the output layer with more than one output, the probability of several outputs\n",
    "\n",
    "The types of output $C$, $(n^{[L]}, 1)$\n",
    "\n",
    "$z^{[L]} = Wa^{[L-1]} + b^{[L]}$\n",
    "\n",
    "$t = e^{z^{[L]}}$, to ensure the outcomes are possitive, $(n^{[L]}, 1)$\n",
    "\n",
    "$a^{[L]} = \\frac{t}{\\sum_{i=1}^{n^{[L]}}t_i}$, to ensure the sum of probabilities is 1\n",
    "\n",
    "Mathematically\\\n",
    "$$a_i = \\frac{e^{z_i}}{\\sum_{j=1}^ne^{z_j}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061531fe",
   "metadata": {},
   "source": [
    "## Back Propagation\n",
    "Loss Function: \n",
    "$$L(a,y) = -\\sum_{i=1}^{n}y_iln(a_i)$$\n",
    "where $y_i$ is the labeled data\\\n",
    "The derivative is\n",
    "$$\\frac{\\partial L}{\\partial a} = -\\sum_i\\frac{y_i}{a_i}$$\n",
    "\n",
    "### Derivative of Softmax Function\n",
    "Calculation of the derivatives of each $a_i$ to one $z_j$.\\\n",
    "The derivatives are different when i = j and i $\\neq$ j.\\\n",
    "When i = j:\n",
    "$$\\frac{\\partial a_j}{\\partial z_j}=\\frac{e^{z_j}\\sum_ke^{z_k}-(e^{z_j})^2}{(\\sum_ke^{z_k})^2}=\\frac{e^{z_j}}{\\sum_ke^{z_k}}-(\\frac{e^{z_j}}{\\sum_ke^{z_k}})^2 = a_j(1-a_j)$$\n",
    "When i $\\neq$ j:\n",
    "$$\\frac{\\partial a_i}{\\partial z_j} = -\\frac{e^{z_i}}{(\\sum_ke^{z_k})^2}e^{z_j} = -\\frac{e^{z_i}}{\\sum_ke^{z_k}}\\frac{e^{z_j}}{\\sum_ke^{z_k}} = -a_ia_j$$\n",
    "\n",
    "### Combination\n",
    "Thus, from Loss function to $z_j$ is simple.\n",
    "$$\\frac{\\partial L}{\\partial z_j} = \\frac{\\partial L}{\\partial a_j}\\frac{\\partial a_j}{\\partial z_j} + \\sum_{i \\neq j}\\frac{\\partial L}{\\partial a_i}\\frac{\\partial a_i}{\\partial z_j}$$\n",
    "$$\\frac{\\partial L}{\\partial z_j} = (-\\frac{y_j}{a_j})\\ a_j(1-a_j) + \\sum_{i \\neq j}(-\\frac{y_i}{a_i})(-a_ia_j)$$\n",
    "$$\\frac{\\partial L}{\\partial z_j} = y_ja_j - y_j + \\sum_{i \\neq j}y_ia_j$$\n",
    "$$\\frac{\\partial L}{\\partial z_j} = \\sum_{i}y_ia_j - y_j$$\n",
    "$$\\frac{\\partial L}{\\partial z_j} = a_j\\sum_{i}y_i - y_j$$\n",
    "Since $\\sum_{i}y_i = 1$,\n",
    "$$\\frac{\\partial L}{\\partial z_j} = a_j - y_j$$\n",
    "\n",
    "Ps. $y_i = 1$ for the correct case and $0$ for the others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c375f980",
   "metadata": {},
   "source": [
    "# tanh\n",
    "$$tanh(x) = \\frac{e^x-e^{-x}}{e^x+e^{-x}}$$\n",
    "$$\\frac{dtanh(x)}{dx} = \\frac{(e^x+e^{-x})^2 - (e^x-e^{-x})^2}{(e^x+e^{-x})^2}$$\n",
    "$$\\frac{dtanh(x)}{dx} = 1 - (\\frac{e^x-e^{-x}}{e^x+e^{-x}})^2$$\n",
    "$$\\frac{dtanh(x)}{dx} = 1 - (tanh(x))^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0db5c2",
   "metadata": {},
   "source": [
    "# Framework\n",
    "## Criteria of choosing framework\n",
    "1. Ease of programming\n",
    "2. Training speed\n",
    "3. Truly open (open source with good governance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c75408",
   "metadata": {},
   "source": [
    "## Tensorflow\n",
    "Automatically compute back propagation\n",
    "Example. Gradient descent to calculate $w$ for Cost function $J = w^2 - 10w + 25$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7930e644",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898c4a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = np.array([1.], [-10.], [25.])\n",
    "\n",
    "w = tf.Variable(0, dtype=tf.float23)\n",
    "#cost = tf.add(tf.add(w**2, tf.multiply(-10., w)), 25)\n",
    "#cost = w**2 - 10w + 25 # operator reloaded\n",
    "x = tf.placeholder(tf.float32, [3, 1]) # use placeholder to be able to feed different data into the model\n",
    "cost = x[0][0]*w**2 + x[1][0]*w + x[2][0]\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost) # 0.01 is the learning rate\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# session = tf.Session()\n",
    "# session.run(init)\n",
    "# print(session.run(w))\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    print(session.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0fb61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One gradient descent\n",
    "session.run(train, feed_dict={x:coefficients}) # feed x with coefficients\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10cc40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000 gradient descents\n",
    "for i in range(1000):\n",
    "    session.run(train, feed_dict={x:coefficients})\n",
    "print(session.run(w))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
