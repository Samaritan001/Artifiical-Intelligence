{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb5f010f",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5125c87f",
   "metadata": {},
   "source": [
    "A manual process to check the dataset and contribute the errors\n",
    "\n",
    "Ceiling: How well the performance will be improved if completely solve one problem (is it worthy), solve the highest percentage first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d0caf7",
   "metadata": {},
   "source": [
    "## Incorrectly Labeled Data\n",
    "### Training Set\n",
    "If nearly random and dataset is large, a few mislabeled data won't affect much\n",
    "\n",
    "While systemetic mislabeled errors are influential\n",
    "\n",
    "Whether to deal with the mislabeled data is based on error analysis\n",
    "\n",
    "### Dev/Test Set\n",
    "When algorithm accuracy increases, the error caused by mislabeled data increasingly affect the judgement of algorithm performances\n",
    "\n",
    "When correcting, not only the wrongly predicted ones but also the right ones need to be checked, though it takes more time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c5b709",
   "metadata": {},
   "source": [
    "# Train and Dev/Test Set from Different Distributions\n",
    "When the established data is abundant while the target data is not, mismatched data distributions\n",
    "\n",
    "Eg. 500,000 professional cat photos from webpage and 20,000 user-taken blurry cat photos from app\n",
    "\n",
    "Add part of the target data (blurry photos) to the training set (professional photos), and split the others into dev and test sets\n",
    "\n",
    "Dev and test set data have to be from the target we care about"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1651a8",
   "metadata": {},
   "source": [
    "## Bias and Variance with Mismatched Data Distributions\n",
    "Harder to determine the reason of the error in dev set, bias/variance or data mismatch problem\n",
    "\n",
    "Solution: train-dev set, a dev set with data come from train-set distribution, to find out bias and variance\n",
    "\n",
    "The error types are\n",
    "1. Human level\n",
    "2. Train set error\n",
    "3. Train-dev set error\n",
    "4. Dev set error\n",
    "5. Test set error\n",
    "\n",
    "The difference between the adjacent errors are Avoidable Bias, Variance, Data Mismatch Problem, and degree of overfitting to dev set\n",
    "\n",
    "When dev and test set data are easier than train set, their error may actually be smaller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf77993",
   "metadata": {},
   "source": [
    "## Solutions to Data Mismatch Problem\n",
    "__Sorry. No systematic solution, only things we can try.__\n",
    "\n",
    "1. Manually analyze the actual difference between train and dev set\n",
    "2. Then make train data more similar to dev set data (Artificial Synthesis Data)\n",
    "\n",
    "Eg.\n",
    "1. Normal speech recording + Car noise = Synthesized in-car audio\n",
    "2. Computer generalized car image\n",
    "\n",
    "Problem to be cautious: synthesized data may only represent a small proportion of the real case, easy for the program to overfit (though noises and cars seem similar to human)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304185f0",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "Apply a well-trained model to a new, similar scenario, especially when we have __a lot of__ data for the problem transfefring from and __less__ data for the problem transferring to.\n",
    "\n",
    "Retrain the parameters in the output layer or more layers or add more layers depening on the amount of data, while the other parameters are unchanged\n",
    "\n",
    "The model is _pre-training_, and the retrain is _fine-tuning_\n",
    "\n",
    "The logic is that the low level features in the pre-trained model serve similar functions when transferred to the new problem, eg. In image recognition the first few layers are about edges, dots, and etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b27b0d",
   "metadata": {},
   "source": [
    "# Multi-task Learning\n",
    "Numerous tasks trained in one model, several outputs but different from Softmax(one task).\n",
    "\n",
    "Eg. Detect in a picture car, pedestrian, traffic light, and stop sign\n",
    "\n",
    "Output: $Y: (4,m)$, $4$ is the number of tasks\n",
    "\n",
    "Cost function: $J = \\frac{1}{m}\\sum_{i=1}^{m}\\sum_{j=1}^{4}L(\\hat{y}^{(i)}_j, y^{(i)}_j)$, $\\ \\ \\ L(\\hat{y}^{(i)}_j, y^{(i)}_j) = -y^{(i)}_j\\log(\\hat{y}^{(i)}_j)-(1-y^{(i)}_j)\\log(1-\\hat{y}^{(i)}_j)$\n",
    "\n",
    "Can handle data without all 4 labels\n",
    "\n",
    "Requirements:\n",
    "1. Tasks of the same kind, can benefit from others\n",
    "2. Similar amount of data for each task\n",
    "3. With a large enough neural network, a multitasking network performs just as good as a single network.\n",
    "\n",
    "Mostly used in CV, usually people use transfer learning than multi-task learning for equally amount of data for several tasks are hard to find."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c18d02",
   "metadata": {},
   "source": [
    "# End-to-end Learning\n",
    "Input to output without a streamline, based on a large neural network and __huge amount of data__\n",
    "\n",
    "__Eg. Speech Recognition__\n",
    "\n",
    "Traditional: audio -> features -> phonemes -> words -> transcript\n",
    "\n",
    "End-to-end: audio ----------------------------------------------> transcript\n",
    "\n",
    "__Eg. Face Recognition__\n",
    "\n",
    "Two steps:\n",
    "1. Crop the face of the person in a image\n",
    "2. Compare the face with official id photo\n",
    "\n",
    "Reason: sufficient training dataset for each of the two tasks\n",
    "\n",
    "## Pros and Cons\n",
    "__Pros__\n",
    "1. Let the data speak (learn freely)\n",
    "2. Less hand-designing of components needed\n",
    "\n",
    "__Cons__\n",
    "1. May need large amount of data\n",
    "2. Excludes potentially useful hand-designed components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f803586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
