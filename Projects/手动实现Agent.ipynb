{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29ecce69",
   "metadata": {},
   "source": [
    "马尔可夫过程\n",
    "1. 状态空间\n",
    "2. 无记忆性\n",
    "3. 转移矩阵\n",
    "\n",
    "Thought - Action - Observation的过程如何拆分并实现\n",
    "1. 理解question要求，根据question决定使用哪个工具，如果都不满足则输出我不会（thought1）\n",
    "2. 调用工具，将输入给到工具（action）\n",
    "3. 工具返回结果（observation）\n",
    "4. 判断结果是否完成question要求（thought2）\n",
    "5. 如果完成则输出答案，如果未完成继续决定使用哪个工具（thought1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb4b923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import date\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06add4d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e26a9a02d0da41c18afeedec659e2932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"C:\\\\Users\\\\By Yu\\\\chatglm-6b\", trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(\"C:\\\\Users\\\\By Yu\\\\chatglm-6b\", trust_remote_code=True).quantize(4).half().cuda()\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7dbd3d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# framework of Agent without method implementations\n",
    "class Agent:\n",
    "    def __init__(self, tool_list): # tool_list is a list of tuples with tool method and description\n",
    "        # build tool dictionaries for functions and descriptions\n",
    "        self.tool_method_dict = {}\n",
    "        self.tool_description_dict = {}\n",
    "        self.thought = [] # lists of dictionaries, each contains tool name, tool input, and reason to take the tool\n",
    "        for tool in tool_list:\n",
    "            name = tool[0].__name__ # get method name\n",
    "            self.tool_method_dict[name] = tool[0]\n",
    "            self.tool_description_dict[name] = tool[1]\n",
    "            \n",
    "    def __str__(self):\n",
    "        return f\"{self.tool_method_dict}\\n{self.tool_description_dict}\"\n",
    "    \n",
    "    def add_tools(self, tool_list):\n",
    "        # add more tools to the agent after initialization\n",
    "        for tool in tool_list:\n",
    "            name = tool[0].__name__ # get method name\n",
    "            if name not in self.tool_method_dict.keys(): # if method exist, don't replace\n",
    "                self.tool_method_dict[name] = tool[0]\n",
    "                self.tool_description_dict[name] = tool[1]\n",
    "    \n",
    "    def replace_tools(self, tool_list):\n",
    "        # replace methods already exist, and add those not\n",
    "        for tool in tool_list:\n",
    "            name = tool[0].__name__ # get method name\n",
    "            self.tool_method_dict[name] = tool[0]\n",
    "            self.tool_description_dict[name] = tool[1]\n",
    "    \n",
    "    def call_tool(self, name, query):\n",
    "        # find and call the specified tool\n",
    "        if name not in self.tool_method_dict.keys():\n",
    "            print(\"Tool not exist. Calling failed. Exit with -1.\")\n",
    "            return -1\n",
    "        return self.tool_method_dict[name](query) # return a string, the output from the tool\n",
    "    \n",
    "    def thought1_decorator(self, func): # is there a matched tool, which tool to use\n",
    "        def inner1(*args, **kwargs):\n",
    "            return_value = func(*args, self.tool_description_dict, **kwargs)\n",
    "            # return_value should be a list\n",
    "            # [0, thought/inference, tool name, tool input query] or\n",
    "            # [-1, thought/inference]\n",
    "            if return_value[0] == -1:\n",
    "                return_value[1] += \"\\nI don't know.\"\n",
    "            return return_value\n",
    "        return inner1\n",
    "    \n",
    "    def thought1_default(self, query=\"\"):\n",
    "        # default thought1 method\n",
    "        prompt = f\"\"\"You are now a tool selector. \\\n",
    "Your job is to select one tool listed below that best performs the task described in the query, in addition to the tools you previously selected.\n",
    "You should not answer the query by yourself.\n",
    "Below is the query, the descriptions of all tools, the tools you've previously selected and their corresponding observations.\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Tool Descriptions:\n",
    "\"\"\"\n",
    "        tool_list = self.tool_description_dict.items()\n",
    "        for description, i in zip(tool_list, np.arange(1, len(tool_list)+1)):\n",
    "            prompt += \"Tool \" + str(i) + \":\\n\"\n",
    "            prompt += \"Name: \" + description[0] + '\\n' + \"Description: \" + description[1] + '\\n\\n'\n",
    "        \n",
    "        prompt += \"Previous Observations:\\n\"\n",
    "        if len(self.thought) == 0:\n",
    "            prompt += \"None.\\n\"\n",
    "        for d, i in zip(self.thought, np.arange(1,len(self.thought)+1)):\n",
    "            prompt += \"Tool \" + str(i) + \": \" + d.get(\"Name\") + '\\n'\n",
    "            prompt += \"Observation \" + str(i) + \": \" + str(d.get(\"Observation\")) + '\\n'\n",
    "        \n",
    "        prompt += \"\"\"\\nYour response has only three lines: the tool name, the input that tool takes, and the reason why you choose this tool. \\\n",
    "The input should have the format defined by the tool description.\n",
    "Please respond in the format:\n",
    "\\\"Name:\n",
    "Input:\n",
    "Reason: \\\"\"\"\"\n",
    "        # If none of the tools match the query, you should respond \\\"I don't know.\\\"\n",
    "        print(prompt)\n",
    "        response, history = model.chat(tokenizer, prompt, history=[])\n",
    "        return response\n",
    "        \n",
    "        \"\"\"\n",
    "        for description in self.tool_description_dict.items():\n",
    "            if description[1] in query:\n",
    "                name = self.tool_method_dict.get(description[0]).__name__\n",
    "                return [0, \"yes! \" + name, name, query]\n",
    "        return [-1, \"No matches for this function, bye!\"]\n",
    "        \"\"\"\n",
    "    \n",
    "    def thought2_decorator(self, func):\n",
    "        def inner2(*args, **kwargs):\n",
    "            return_value = func(*args, **kwargs)\n",
    "            return return_value\n",
    "            # return_value should be a list\n",
    "            # [0, thought/inference, answer] or\n",
    "            # [1, thought/inference, final answer]\n",
    "        return inner2\n",
    "    \n",
    "    def thought2_default(self, query):\n",
    "        # default thought2 method\n",
    "        prompt = f\"\"\"You are now a judge of several observations. \\\n",
    "Your job is to decide whether the observations listed below are sufficient to answer the question described in the query.\n",
    "Below is the query, the tools you used, and the corresponding obervations.\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Tools and Observations:\n",
    "\"\"\"\n",
    "\n",
    "        for d, i in zip(self.thought, np.arange(1,len(self.thought)+1)):\n",
    "            prompt += \"Tool \" + str(i) + \": \" + d.get(\"Name\") + '\\n'\n",
    "            prompt += \"Observation \" + str(i) + \": \" + str(d.get(\"Observation\")) + '\\n'\n",
    "\n",
    "        prompt += \"\"\"\\nYour response has only one line: an answer.\\\n",
    "If the observations are good enough to meet the query's need, \\\n",
    "your response should be \\\"good\\\"; if the observations are not good enough, your response should be \\\"continue\\\".\n",
    "Please respond in the format:\n",
    "\\\"Answer: \\\"\"\"\"\n",
    "        \n",
    "        print(prompt)\n",
    "        response, history = model.chat(tokenizer, prompt, history=[])\n",
    "        return response\n",
    "    \n",
    "    def output(self):\n",
    "        final_output = \"\"\n",
    "        for d in self.thought:\n",
    "            final_output += str(d.get(\"Observation\")) + '\\n'\n",
    "        return final_output\n",
    "    \n",
    "    \"\"\"\n",
    "    def concatenate(self, query, inference, observation):\n",
    "        # combine the query, inferences and observations into one new prompt\n",
    "        prompt = query + '\\n\\n'\n",
    "        for i in range(0, len(inference)-1, 2):\n",
    "            prompt += inference[i] + '\\n' + str(observation[i//2]) + '\\n' + inference[i+1] + '\\n\\n'\n",
    "        return prompt\n",
    "    \"\"\"\n",
    "    \n",
    "    def run(self, query, thought1 = thought1_default, thought2 = thought2_default):\n",
    "        self.thought = []\n",
    "        i = 1\n",
    "        while True:\n",
    "            # thought 1\n",
    "            if thought1.__name__ == self.thought1_default.__name__:\n",
    "                self.thought.append(str_to_dict(thought1(self, query=query))) \n",
    "            else:\n",
    "                self.thought.append(str_to_dict(thought1(query=prompt)))\n",
    "            print(\"\\nthought {}\\n{}\".format(i, self.thought[-1]), end='\\n\\n')\n",
    "            \n",
    "            # action\n",
    "            \"\"\"\n",
    "            if self.thought[i][0] == -1:\n",
    "                return self.output(final_output=self.thought[i][2]) # I don't know\n",
    "            \n",
    "            \"\"\"\n",
    "            observation = self.call_tool(name=self.thought[-1].get(\"Name\"), query=self.thought[-1].get(\"Input\"))\n",
    "            self.thought[-1][\"Observation\"] = observation\n",
    "            # print(\"observation\", i//2, self.observation[-1])\n",
    "            \n",
    "            # thought 2\n",
    "            self.thought[-1][\"Answer\"] = ''\n",
    "            while self.thought[-1].get(\"Answer\") == '': # continues to judge if no output answer\n",
    "                if thought2.__name__ == self.thought2_default.__name__:\n",
    "                    answer = thought2(self, query=query)\n",
    "                    print(answer)\n",
    "                    answer = str_to_dict(answer)\n",
    "                    self.thought[-1][\"Answer\"] = answer.get(\"Answer\")\n",
    "                    print(\"\\nthought {}\\n{}\".format(i, self.thought[-1]), end='\\n\\n')\n",
    "                else:\n",
    "                    answer = str_to_dict(thought2(query=query))\n",
    "                    self.thought[-1][\"Answer\"] = answer.get(\"Answer\")\n",
    "                    print(\"\\nthought {}\\n{}\".format(i, self.thought[-1]), end='\\n\\n')\n",
    "                \n",
    "            if \"continue\" not in self.thought[-1].get(\"Answer\").lower(): # exit if final answer is given\n",
    "                break\n",
    "            i += 1\n",
    "        \n",
    "        return self.output()\n",
    "        # output(self.thought[-1][-1]) # output final answer\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8938a1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returns todays date, use this for any questions related to knowing todays date. The input should always be an empty string, and this function will always return todays data - any date mathmatics should occur outside this function.\n"
     ]
    }
   ],
   "source": [
    "def find_date(query=\"\"):\n",
    "    return str(date.today())\n",
    "\n",
    "find_date_description = \"\"\"Returns todays date, use this for any \\\n",
    "questions related to knowing todays date. \\\n",
    "The input should always be an empty string, \\\n",
    "and this function will always return todays \\\n",
    "data - any date mathmatics should occur \\\n",
    "outside this function.\"\"\"\n",
    "print(find_date_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7e5f9101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_rand(query = \"01\"):\n",
    "    num_list = re.findall('\\d+', query)\n",
    "    if len(num_list) < 2:\n",
    "        return float(\"-inf\")\n",
    "    a = int(min(num_list[0], num_list[1]))\n",
    "    b = int(max(num_list[0], num_list[1]))\n",
    "    return random.randint(a, b)\n",
    "\n",
    "gen_rand_description = \"\"\"Return a random integer, use this for any \\\n",
    "query for a random value within a given range.\\\n",
    "The input is a pair of two integers, representing \\\n",
    "the random bound, and the two integers are given by the query. \\\n",
    "This function will always return a randomly generated integer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "78193350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-28\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(find_date())\n",
    "print(gen_rand(\"Give me a random number between 1 and 10.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f8349029",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(tool_list=[(find_date, find_date_description)])\n",
    "agent.add_tools(tool_list=[(gen_rand, gen_rand_description)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2f5c8f8b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are now a tool selector. Your job is to select one tool listed below that best performs the task described in the query, in addition to the tools you previously selected.\n",
      "You should not answer the query by yourself.\n",
      "Below is the query, the descriptions of all tools, the tools you've previously selected and their corresponding observations.\n",
      "\n",
      "Query: Give me a random integer between (3, 9).\n",
      "\n",
      "Tool Descriptions:\n",
      "Tool 1:\n",
      "Name: find_date\n",
      "Description: Returns todays date, use this for any questions related to knowing todays date. The input should always be an empty string, and this function will always return todays data - any date mathmatics should occur outside this function.\n",
      "\n",
      "Tool 2:\n",
      "Name: gen_rand\n",
      "Description: Return a random integer, use this for any query for a random value within a given range.The input is a pair of two integers, representing the random bound, and the two integers are given by the query. This function will always return a randomly generated integer.\n",
      "\n",
      "\n",
      "Previous Observations:\n",
      "None.\n",
      "\n",
      "Your response has only three lines: the tool name, the input that tool takes, and the reason why you choose this tool. The input should have the format defined by the tool description.\n",
      "Please respond in the format:\n",
      "\"Name:\n",
      "Input:\n",
      "Reason: \"\n",
      "\n",
      "thought 1\n",
      "{'Name': 'gen_rand', 'Input': '(3, 9)', 'Reason': 'This tool is best suited for generating a random integer between (3, 9) as it takes a pair of integers as input, which is the format defined by the tool description.'}\n",
      "\n",
      "You are now a judge of several observations. Your job is to decide whether the observations listed below are sufficient to answer the question described in the query.\n",
      "Below is the query, the tools you used, and the corresponding obervations.\n",
      "\n",
      "Query: Give me a random integer between (3, 9).\n",
      "\n",
      "Tools and Observations:\n",
      "Tool 1: gen_rand\n",
      "Observation 1: 4\n",
      "\n",
      "Your response has only one line: an answer.If the observations are good enough to meet the query's need, your response should be \"good\"; if the observations are not good enough, your response should be \"continue\".\n",
      "Please respond in the format:\n",
      "\"Answer: \"\n",
      "Answer: good\n",
      "\n",
      "thought 1\n",
      "{'Name': 'gen_rand', 'Input': '(3, 9)', 'Reason': 'This tool is best suited for generating a random integer between (3, 9) as it takes a pair of integers as input, which is the format defined by the tool description.', 'Observation': 4, 'Answer': 'good'}\n",
      "\n",
      "\n",
      "Answer\n",
      "4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer = agent.run(query=\"Give me a random integer between (3, 9).\")\n",
    "print(f\"\\nAnswer\\n{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a11e2d8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are now a tool selector. Your job is to select one tool listed below that best performs the task described in the query, in addition to the tools you previously selected.\n",
      "You should not answer the query by yourself.\n",
      "Below is the query, the descriptions of all tools, the tools you've previously selected and their corresponding observations.\n",
      "\n",
      "Query: I want to know what date is it today.\n",
      "\n",
      "Tool Descriptions:\n",
      "Tool 1:\n",
      "Name: find_date\n",
      "Description: Returns todays date, use this for any questions related to knowing todays date. The input should always be an empty string, and this function will always return todays data - any date mathmatics should occur outside this function.\n",
      "\n",
      "Tool 2:\n",
      "Name: gen_rand\n",
      "Description: Return a random integer, use this for any query for a random value within a given range.The input should always be a string with two integers representing the bound required in the query, and the two integers are separated with a comma, and this function will always return a randomly generated integer.\n",
      "\n",
      "\n",
      "Previous Observations:\n",
      "None.\n",
      "\n",
      "Your response has only three lines: the tool name, the input that tool takes, and the reason why you choose this tool. The input should have the format defined by the tool description.\n",
      "Please respond in the format:\n",
      "\"Name:\n",
      "Input:\n",
      "Reason: \"\n",
      "\n",
      "Response\n",
      "Name: find_date\n",
      "Input: an empty string\n",
      "Reason: This tool is the best suited for the task of finding today's date as it only requires an input of an empty string, and it will always return today's date. The other tool, gen_rand, requires the input to be a string with two integers representing the bound required in the query, which can be prone to errors if not properly formatted.\n"
     ]
    }
   ],
   "source": [
    "response = agent.thought1_default(query=\"I want to know what date is it today.\")\n",
    "print(f\"\\nResponse\\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9769c883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_dict(string):\n",
    "    items = string.split('\\n')\n",
    "    dictionary = {}\n",
    "    for i in items:\n",
    "        key_value = i.split(':')\n",
    "        # print(\"key_value:\", key_value)\n",
    "        if key_value[1] == '':\n",
    "            dictionary[key_value[0]] = ''\n",
    "        elif key_value[1][0] != \" \" or len(key_value[1]) == 1:\n",
    "            dictionary[key_value[0]] = key_value[1]\n",
    "        else:\n",
    "            dictionary[key_value[0]] = key_value[1][1:]\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8bcf7148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('Name', 'find_date'), ('Input', ''), ('Reason', \"This tool will always return today's date.\")])\n"
     ]
    }
   ],
   "source": [
    "response = \"\"\"Name: find_date\n",
    "Input:\n",
    "Reason: This tool will always return today's date.\"\"\"\n",
    "d = str_to_dict(response)\n",
    "print(d.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f35ff435",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ agent.thought2_decorator\n",
    "def random_exit(query=\"\"):\n",
    "    query_list = query.split('\\n')\n",
    "    if random.random() > 0.5:\n",
    "        return [0, f\"Please continue\\n{query_list[0]}\", query_list[2]]\n",
    "    return [1, \"Finished!\", query_list[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "44534c3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thought 0 [0, 'yes! gen_rand', 'gen_rand', 'Give me a random number between 1 and 10']\n",
      "inference 0 yes! gen_rand\n",
      "observation 0 2\n",
      "thought 1 [0, 'Please continue\\nGive me a random number between 1 and 10', '']\n",
      "inference 1 Please continue\n",
      "Give me a random number between 1 and 10\n",
      "thought 2 [0, 'yes! gen_rand', 'gen_rand', 'Give me a random number between 1 and 10\\n\\nyes! gen_rand\\n2\\nPlease continue\\nGive me a random number between 1 and 10\\n\\n']\n",
      "inference 2 yes! gen_rand\n",
      "observation 1 6\n",
      "thought 3 [1, 'Finished!', 'yes! gen_rand']\n",
      "inference 3 Finished!\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "result = agent.run(\"Give me a random number between 1 and 10\", thought2=random_exit)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "53e06dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff5f86ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ah\n"
     ]
    }
   ],
   "source": [
    "if \"random\" in \"aijsdifj randomnesss\":\n",
    "    print(\"ah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c18630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062443c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5eed3eec",
   "metadata": {},
   "source": [
    "Test class initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3417cc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "def abc():\n",
    "    print(\"hello\")\n",
    "dic = {\"a\": abc}\n",
    "dic.get(\"a\")()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85abbc64",
   "metadata": {},
   "source": [
    "Test class \\_\\_str\\_\\_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7cf65aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Agent([(abc, \"asuhuhdd\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e0f15195",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abc': <function abc at 0x000002A724CBD9D0>}\n",
      "{'abc': 'asuhuhdd'}\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91714981",
   "metadata": {},
   "source": [
    "Test in-class decorator function calling class variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a0765bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ a.thought1\n",
    "def print_lahoho(a, b, c):\n",
    "    print(\"lahoho\")\n",
    "    print(\"a: \", a)\n",
    "    print(\"b: \", b)\n",
    "    print(\"c: \", c)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "07f0b3b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abc': <function abc at 0x000002A724CBD9D0>}\n",
      "lahoho\n",
      "a:  3\n",
      "b:  {'abc': 'asuhuhdd'}\n",
      "c:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_lahoho(3, c=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f8fb5e",
   "metadata": {},
   "source": [
    "Testing decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "32db497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person:\n",
    "    def __init__(self):\n",
    "        self.name = \"Michael\"\n",
    "    \n",
    "    def dec(func):\n",
    "        def inner(*args, **kwargs):\n",
    "            return_value = func(*args, **kwargs)\n",
    "            return return_value\n",
    "        return inner\n",
    "    \n",
    "    @ dec\n",
    "    def lulula(self, name):\n",
    "        print(self.name)\n",
    "        print(name)\n",
    "        return 0\n",
    "    \n",
    "    def call_name(self, name, func=lulula):\n",
    "        if func.__name__ == self.lulula.__name__:\n",
    "            print(\"hello lulula\")\n",
    "            func(self, name)\n",
    "        else:\n",
    "            func(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b1fb8708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polite(name=\"Peter\"):\n",
    "    print(f\"Hi, my name is {name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f7efbafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael\n",
      "Gloria\n",
      "Hi, my name is Peter.\n",
      "hello lulula\n",
      "Michael\n",
      "Jack\n"
     ]
    }
   ],
   "source": [
    "michael = Person()\n",
    "michael.lulula(\"Gloria\")\n",
    "michael.call_name(name=\"Peter\", func=polite)\n",
    "michael.call_name(name=\"Jack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95b10f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dectest(func):\n",
    "    def inner(*args, **kwargs):\n",
    "        return_value = func(*args, **kwargs)\n",
    "        return return_value\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5ab2fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_holala():\n",
    "    print(\"holala\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "13e5eb2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (266413596.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[83], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    def print_holala\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "@ dectest\n",
    "print_holala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1279157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are now asked to perform one or many tasks with the tools you have. \n",
      "Below is the query and the tool description\n"
     ]
    }
   ],
   "source": [
    "test = \"\"\"You are now asked to perform one or many tasks with the tools you have. \n",
    "Below is the query and the tool description\"\"\"\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7a425eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-inf\n"
     ]
    }
   ],
   "source": [
    "print(float(\"-inf\")+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98565eff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
